{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAN THESIS\n",
    "This here is basic start of KAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Colab env\n",
    "Uploading and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0 \\\n",
    "pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up the Environment\n",
    "Starting with libs and setting up device. If possible use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from kan import KAN\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch -> PyTorch deeplearning framework, core funcionality\n",
    "torchvision -> Utilities for loading and transforming image datasets as MNIST\n",
    "kan -> Library contating implementation of KAN\n",
    "I also set a dtype for float64 for bigg precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess the MNIST Dataset\n",
    "We're loading MNIST dataset and apply all transformation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #normalizing dataset \n",
    "    ]) \n",
    "\n",
    "#Download MNIST dataset and used the transform to convert the data to tensor and normalize it\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create DataLoader to batch and shuffle the data using mulitprocessing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4096, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToTensor -> Convert images to PyTorch tensors\n",
    "Normalize -> Normalizing MNIST dataset using the mean and standard deviation for each channel. This are values specifc for MNIST dataset:\n",
    "                0.1307 -> Number of mean pixel in all MNIST pictures \n",
    "                0.3081 -> Standard deviation of pixel for each channel. (Values specific to MNIST)\n",
    "DataLoader -> Batch_size=2048 -> Size of batch optimize for training \n",
    "            Shuffle=True -> Data are randomly mixed before each epoch of traing. This make sure that our model does not learn the sequence of data insted of acutal data.\n",
    "            Num_workser=4 -> Process of loading data is going on 4 threads. It helps to speed up loading time when data are too big or they require time consuming operation\n",
    "            Pin_memory=True -> It alows data to being passed to RAM (used with GPU training)\n",
    "Train_loader -> Dataset used for training\n",
    "Test_loader -> Dataset used for measuering performacne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the KAN Model\n",
    "Here we create our KAN model with dimension for MNIST dataset.\n",
    "Input set is only 784 pixels (images 28x28) and output size is 10\n",
    "Parameters\n",
    "Hidden layers -> More neurons may risk in overfitting\n",
    "Grid -> More finner adjustment but more prone to overfitting\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KAN model\n",
    "#Input layer = 784, hidden layer1 = 128, hidden layer2 = 64, output layer = 10\n",
    "#Grid = 5, k = 3, seed = 42 \n",
    "#and move model to device\n",
    "#model = KAN(width=[784, 32, 16, 10], grid=5, k=3, seed=42, device=device).to(device)\n",
    "model = KAN(width=[392, 16, 8, 5], grid=5, k=3, seed=42, device=device).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Loss Function and Optimizer\n",
    "CrossEntropyLoss for classification and Adam optimizer for training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer // think about this params and below\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    " #from 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "This cell contains the training loop where the model is trained for a specified number of epochs. \n",
    "The loss is printed after each epoch to monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you track loss and accuracy in lists during training\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f'KAN Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Save training loss\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f'KAN Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model\n",
    "Finally, we evaluate the trained model on the test set to see how well it performs. The accuracy is calculated and printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few test set predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.view(images.size(0), -1).to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show a few images and their predictions\n",
    "images = images.view(-1, 28, 28).cpu().numpy()\n",
    "labels = labels.cpu().numpy()\n",
    "predicted = predicted.cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(f'Pred: {predicted[i]}, True: {labels[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
