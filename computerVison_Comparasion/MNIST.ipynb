{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Colab env\n",
    "Uploading and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting archspec==0.2.3\n",
      "  Using cached archspec-0.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.4.1)\n",
      "Collecting boltons==23.0.0\n",
      "  Using cached boltons-23.0.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Brotli==1.0.9\n",
      "  Using cached Brotli-1.0.9.zip (510 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting charset-normalizer==2.0.4\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.2)\n",
      "Collecting cryptography==42.0.5\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting distro==1.9.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting executing==2.0.1\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting frozendict==2.4.2\n",
      "  Using cached frozendict-2.4.2-cp312-cp312-win_amd64.whl\n",
      "Collecting idna==3.7\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.19.1)\n",
      "Collecting jsonpatch==1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer==2.1\n",
      "  Using cached jsonpointer-2.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (1.6.0)\n",
      "Collecting packaging==23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.8.4)\n",
      "Collecting platformdirs==4.2.1\n",
      "  Using cached platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pluggy==1.0.0\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pycosat==0.6.6\n",
      "  Using cached pycosat-0.6.6.tar.gz (71 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: Pygments==2.18.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.18.0)\n",
      "Collecting PySocks==1.7.1\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting ruamel.yaml==0.17.21\n",
      "  Using cached ruamel.yaml-0.17.21-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.6.3)\n",
      "Collecting tqdm==4.66.4\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (5.14.3)\n",
      "Collecting truststore==0.8.0\n",
      "  Using cached truststore-0.8.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting urllib3==2.2.2\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting zstandard==0.22.0\n",
      "  Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pykan in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (from asttokens==2.4.1) (1.16.0)\n",
      "Collecting cffi>=1.12 (from cryptography==42.0.5)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.32.3)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached archspec-0.2.3-py3-none-any.whl (65 kB)\n",
      "Using cached boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
      "Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached platformdirs-4.2.1-py3-none-any.whl (17 kB)\n",
      "Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached truststore-0.8.0-py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl (511 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Building wheels for collected packages: Brotli, pycosat\n",
      "  Building wheel for Brotli (pyproject.toml): started\n",
      "  Building wheel for Brotli (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for pycosat (pyproject.toml): started\n",
      "  Building wheel for pycosat (pyproject.toml): finished with status 'error'\n",
      "Failed to build Brotli pycosat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for Brotli (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [26 lines of output]\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-5dtgt1tf\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-5dtgt1tf\\overlay\\Lib\\site-packages\\setuptools\\dist.py:495: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'build-base' will not be supported in future\n",
      "              versions. Please use the underscore name 'build_base' instead.\n",
      "      \n",
      "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating bin\\lib.win-amd64-cpython-312\n",
      "      copying python\\brotli.py -> bin\\lib.win-amd64-cpython-312\n",
      "      running build_ext\n",
      "      <string>:67: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "      building '_brotli' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Brotli\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pycosat (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycosat\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (Brotli, pycosat)\n"
     ]
    }
   ],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0 \\\n",
    "pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up the Environment\n",
    "Starting with libs and setting up device. If possible use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from kan import KAN\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #normalizing dataset \n",
    "    ]) \n",
    "\n",
    "#Download MNIST dataset and used the transform to convert the data to tensor and normalize it\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create DataLoader to batch and shuffle the data using mulitprocessing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4096, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(width) - 1):\n",
    "            layers.append(nn.Linear(width[i], width[i+1]))\n",
    "            if i < len(width) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the MLP modelMLP\n",
    "modelMLP = MLP(width=[784, 32, 16, 10]).to(device).float()\n",
    "modelKAN = KAN(width=[784, 32, 16, 10], grid=5, k=3, seed=42, device=device).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizerMLP = torch.optim.Adam(modelMLP.parameters(), lr=0.002)\n",
    "optimizerKAN = torch.optim.Adam(modelKAN.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  20%|██        | 3/15 [00:56<03:39, 18.27s/it]"
     ]
    }
   ],
   "source": [
    "scalerMLP = torch.cuda.amp.GradScaler('cuda')\n",
    "scalerKAN = torch.cuda.amp.GradScaler('cuda')\n",
    "train_losses_MLP = []\n",
    "train_losses_KAN = []\n",
    "test_accuracies_MLP = []\n",
    "test_accuracies_KAN = []\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1  # Set to 1 for initial testing; adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set both models to training mode\n",
    "    modelMLP.train()\n",
    "    modelKAN.train()\n",
    "\n",
    "    # Initialize running loss and correct predictions counters\n",
    "    running_loss_MLP = 0.0\n",
    "    running_loss_KAN = 0.0\n",
    "    correct_MLP = 0\n",
    "    correct_KAN = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        # Move data to the configured device and flatten images\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ####### Training MLP #######\n",
    "        optimizerMLP.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=device_type, enabled=torch.cuda.is_available()):\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            loss_MLP = criterion(outputs_MLP, labels)\n",
    "\n",
    "        scalerMLP.scale(loss_MLP).backward()  # Backward pass for MLP\n",
    "        scalerMLP.step(optimizerMLP)          # Update MLP parameters\n",
    "        scalerMLP.update()\n",
    "\n",
    "        running_loss_MLP += loss_MLP.item() \n",
    "\n",
    "        _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "        correct_MLP += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "        ####### Training KAN #######\n",
    "        optimizerKAN.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=device_type, enabled=torch.cuda.is_available()):\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            loss_KAN = criterion(outputs_KAN, labels)\n",
    "\n",
    "        scalerKAN.scale(loss_KAN).backward()  # Backward pass for KAN\n",
    "        scalerKAN.step(optimizerKAN)           # Update KAN parameters\n",
    "        scalerKAN.update()\n",
    "\n",
    "        running_loss_KAN += loss_KAN.item()    # Accumulate KAN loss\n",
    "\n",
    "        _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "        correct_KAN += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate average losses for the epoch\n",
    "    avg_loss_MLP = running_loss_MLP / len(train_loader)\n",
    "    avg_loss_KAN = running_loss_KAN / len(train_loader)\n",
    "\n",
    "    train_losses_MLP.append(avg_loss_MLP)\n",
    "    train_losses_KAN.append(avg_loss_KAN)\n",
    "\n",
    "    ####### Evaluation #######\n",
    "    # Set both models to evaluation mode\n",
    "    modelMLP.eval()\n",
    "    modelKAN.eval()\n",
    "\n",
    "    correct_MLP_test = 0\n",
    "    correct_KAN_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Evaluate MLP\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "            correct_MLP_test += (predicted_MLP == labels).sum().item()\n",
    "            \n",
    "            # Evaluate KAN\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "            correct_KAN_test += (predicted_KAN == labels).sum().item()\n",
    "            \n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    # Calculate test accuracies\n",
    "    test_accuracy_MLP = 100 * correct_MLP_test / total_test\n",
    "    test_accuracy_KAN = 100 * correct_KAN_test / total_test\n",
    "\n",
    "    test_accuracies_MLP.append(test_accuracy_MLP)\n",
    "    test_accuracies_KAN.append(test_accuracy_KAN)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'| MLP Loss: {avg_loss_MLP:.4f} | MLP Test Acc: {test_accuracy_MLP:.2f}% '\n",
    "          f'| KAN Loss: {avg_loss_KAN:.4f} | KAN Test Acc: {test_accuracy_KAN:.2f}%')\n",
    "\n",
    "####### Plotting #######\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Training Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses_MLP, label='MLP Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), train_losses_KAN, label='KAN Training Loss', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Test Accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_MLP, label='MLP Test Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_KAN, label='KAN Test Accuracy', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
