{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Colab env\n",
    "Uploading and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting archspec==0.2.3\n",
      "  Using cached archspec-0.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.4.1)\n",
      "Collecting boltons==23.0.0\n",
      "  Using cached boltons-23.0.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Brotli==1.0.9\n",
      "  Using cached Brotli-1.0.9.zip (510 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting charset-normalizer==2.0.4\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.2)\n",
      "Collecting cryptography==42.0.5\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting distro==1.9.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting executing==2.0.1\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting frozendict==2.4.2\n",
      "  Using cached frozendict-2.4.2-cp312-cp312-win_amd64.whl\n",
      "Collecting idna==3.7\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.19.1)\n",
      "Collecting jsonpatch==1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer==2.1\n",
      "  Using cached jsonpointer-2.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (1.6.0)\n",
      "Collecting packaging==23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.8.4)\n",
      "Collecting platformdirs==4.2.1\n",
      "  Using cached platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pluggy==1.0.0\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pycosat==0.6.6\n",
      "  Using cached pycosat-0.6.6.tar.gz (71 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: Pygments==2.18.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.18.0)\n",
      "Collecting PySocks==1.7.1\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting ruamel.yaml==0.17.21\n",
      "  Using cached ruamel.yaml-0.17.21-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.6.3)\n",
      "Collecting tqdm==4.66.4\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (5.14.3)\n",
      "Collecting truststore==0.8.0\n",
      "  Using cached truststore-0.8.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting urllib3==2.2.2\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting zstandard==0.22.0\n",
      "  Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pykan in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (from asttokens==2.4.1) (1.16.0)\n",
      "Collecting cffi>=1.12 (from cryptography==42.0.5)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.32.3)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached archspec-0.2.3-py3-none-any.whl (65 kB)\n",
      "Using cached boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
      "Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached platformdirs-4.2.1-py3-none-any.whl (17 kB)\n",
      "Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached truststore-0.8.0-py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl (511 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Building wheels for collected packages: Brotli, pycosat\n",
      "  Building wheel for Brotli (pyproject.toml): started\n",
      "  Building wheel for Brotli (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for pycosat (pyproject.toml): started\n",
      "  Building wheel for pycosat (pyproject.toml): finished with status 'error'\n",
      "Failed to build Brotli pycosat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for Brotli (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [26 lines of output]\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-9ras2ran\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:270: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-9ras2ran\\overlay\\Lib\\site-packages\\setuptools\\dist.py:493: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'build-base' will not be supported in future\n",
      "              versions. Please use the underscore name 'build_base' instead.\n",
      "      \n",
      "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating bin\\lib.win-amd64-cpython-312\n",
      "      copying python\\brotli.py -> bin\\lib.win-amd64-cpython-312\n",
      "      running build_ext\n",
      "      <string>:67: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "      building '_brotli' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Brotli\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pycosat (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycosat\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (Brotli, pycosat)\n"
     ]
    }
   ],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0 \\\n",
    "thop==0.0.31.post2005241907 \\\n",
    "pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up the Environment\n",
    "Starting with libs and setting up device. If possible use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile  \u001b[38;5;66;03m# For FLOPs calculation (pip install thop)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KAN  \u001b[38;5;66;03m# Make sure your KAN implementation is available\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thop'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from thop import profile  # For FLOPs calculation (pip install thop)\n",
    "\n",
    "from kan import KAN  # Make sure your KAN implementation is available\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "use_amp = torch.cuda.is_available()\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #normalizing dataset \n",
    "    ]) \n",
    "\n",
    "#Download MNIST dataset and used the transform to convert the data to tensor and normalize it\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create DataLoader to batch and shuffle the data using mulitprocessing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4096, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(width) - 1):\n",
    "            layers.append(nn.Linear(width[i], width[i+1]))\n",
    "            if i < len(width) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the MLP modelMLP\n",
    "modelMLP = MLP(width=[784, 10]).to(device)  \n",
    "modelKAN = KAN(width=[784, 10], grid=3, k=2, seed=42, device=device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizerMLP = torch.optim.Adam(modelMLP.parameters(), lr=0.001, weight_decay=1e-4) \n",
    "optimizerKAN = torch.optim.Adam(modelKAN.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = torch.cuda.is_available()\n",
    "\n",
    "scalerMLP = GradScaler(device='cuda', enabled=use_amp)\n",
    "scalerKAN = GradScaler(device='cuda', enabled=use_amp)\n",
    "\n",
    "train_losses_MLP = []\n",
    "train_losses_KAN = []\n",
    "test_accuracies_MLP = []\n",
    "test_accuracies_KAN = []\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "train_losses_MLP = []\n",
    "train_losses_KAN = []\n",
    "test_accuracies_MLP = []\n",
    "test_accuracies_KAN = []\n",
    "\n",
    "####################################\n",
    "# 6. Main Training / Evaluation    #\n",
    "####################################\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Set both models to training mode\n",
    "    modelMLP.train()\n",
    "    modelKAN.train()\n",
    "\n",
    "    running_loss_MLP = 0.0\n",
    "    running_loss_KAN = 0.0\n",
    "\n",
    "    correct_MLP = 0\n",
    "    correct_KAN = 0\n",
    "    total = 0\n",
    "\n",
    "    # ---------- Training Loop ----------\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        # Move data to device\n",
    "        images = images.view(images.size(0), -1).to(device)  # Flatten for MLP/KAN\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ##### Train MLP #####\n",
    "        optimizerMLP.zero_grad()\n",
    "        with torch.autocast(device_type=device_type, enabled=use_amp):\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            loss_MLP = criterion(outputs_MLP, labels)\n",
    "        scalerMLP.scale(loss_MLP).backward()\n",
    "        scalerMLP.step(optimizerMLP)\n",
    "        scalerMLP.update()\n",
    "\n",
    "        running_loss_MLP += loss_MLP.item()\n",
    "        _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "        correct_MLP += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "        ##### Train KAN #####\n",
    "        optimizerKAN.zero_grad()\n",
    "        with torch.autocast(device_type=device_type, enabled=use_amp):\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            loss_KAN = criterion(outputs_KAN, labels)\n",
    "        scalerKAN.scale(loss_KAN).backward()\n",
    "        scalerKAN.step(optimizerKAN)\n",
    "        scalerKAN.update()\n",
    "\n",
    "        running_loss_KAN += loss_KAN.item()\n",
    "        _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "        correct_KAN += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Compute training losses\n",
    "    avg_loss_MLP = running_loss_MLP / len(train_loader)\n",
    "    avg_loss_KAN = running_loss_KAN / len(train_loader)\n",
    "    train_losses_MLP.append(avg_loss_MLP)\n",
    "    train_losses_KAN.append(avg_loss_KAN)\n",
    "\n",
    "    # ---------- Evaluation / Testing Loop ----------\n",
    "    modelMLP.eval()\n",
    "    modelKAN.eval()\n",
    "\n",
    "    correct_MLP_test = 0\n",
    "    correct_KAN_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # MLP\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "            correct_MLP_test += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "            # KAN\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "            correct_KAN_test += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    # Calculate test accuracies\n",
    "    test_accuracy_MLP = 100 * correct_MLP_test / total_test\n",
    "    test_accuracy_KAN = 100 * correct_KAN_test / total_test\n",
    "\n",
    "    test_accuracies_MLP.append(test_accuracy_MLP)\n",
    "    test_accuracies_KAN.append(test_accuracy_KAN)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'| MLP Loss: {avg_loss_MLP:.4f} | MLP Test Acc: {test_accuracy_MLP:.2f}% '\n",
    "          f'| KAN Loss: {avg_loss_KAN:.4f} | KAN Test Acc: {test_accuracy_KAN:.2f}% '\n",
    "          f'| Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "##############################################\n",
    "# 7. Plotting: Training Loss & Test Accuracy #\n",
    "##############################################\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# -- Training Losses --\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses_MLP, label='MLP Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), train_losses_KAN, label='KAN Training Loss', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# -- Test Accuracies --\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_MLP, label='MLP Test Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_KAN, label='KAN Test Accuracy', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##############################\n",
    "# 8. Additional Functionality #\n",
    "##############################\n",
    "\n",
    "# 8a. Feature Importance for KAN\n",
    "def feature_importance(kan_model):\n",
    "    \"\"\"\n",
    "    Sums absolute spline coefficients for each input feature and plots as a bar graph.\n",
    "    This assumes your KAN implementation has 'kan_model.layers[0].splines' accessible.\n",
    "    Adjust accordingly based on how your KAN code is structured.\n",
    "    \"\"\"\n",
    "    # Example: sum of absolute values of the first layer's spline coefficients\n",
    "    importance = torch.abs(kan_model.layers[0].splines).sum(dim=0)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.bar(range(importance.size(0)), importance.cpu().detach().numpy())\n",
    "    plt.title('Input Feature Importance (KAN)')\n",
    "    plt.xlabel('Pixel Position')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "\n",
    "# Call feature_importance after training if you like:\n",
    "feature_importance(modelKAN)\n",
    "\n",
    "# 8b. Model Size (Parameters, Memory) \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "mlp_params = count_parameters(modelMLP)\n",
    "kan_params = count_parameters(modelKAN)\n",
    "\n",
    "print(f\"MLP Parameters: {mlp_params:,}\")\n",
    "print(f\"KAN Parameters: {kan_params:,}\")\n",
    "\n",
    "# Float32 => 4 bytes per parameter\n",
    "print(f\"MLP Memory: {mlp_params * 4 / 1e6:.2f} MB\")\n",
    "print(f\"KAN Memory: {kan_params * 4 / 1e6:.2f} MB\")\n",
    "\n",
    "# 8c. Inference Speed (on the test loader) - measure total or per batch\n",
    "with torch.no_grad():\n",
    "    # MLP\n",
    "    start_infer_mlp = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        _ = modelMLP(images)\n",
    "    mlp_infer_time = time.time() - start_infer_mlp\n",
    "\n",
    "    # KAN\n",
    "    start_infer_kan = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        _ = modelKAN(images)\n",
    "    kan_infer_time = time.time() - start_infer_kan\n",
    "\n",
    "print(f\"MLP Inference Time (total over test set): {mlp_infer_time:.4f}s\")\n",
    "print(f\"KAN Inference Time (total over test set): {kan_infer_time:.4f}s\")\n",
    "\n",
    "# 8d. GPU Memory Usage\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "# 8e. Confusion Matrix\n",
    "def plot_confusion_matrix(model, loader, model_name=\"Model\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(modelMLP, test_loader, \"MLP\")\n",
    "plot_confusion_matrix(modelKAN, test_loader, \"KAN\")\n",
    "\n",
    "# 8f. Parameter Distribution\n",
    "def plot_weights(model, title):\n",
    "    weights = []\n",
    "    for param in model.parameters():\n",
    "        if param.dim() > 1:  # Skip biases (dim=1)\n",
    "            weights.extend(param.flatten().cpu().detach().numpy())\n",
    "    plt.hist(weights, bins=50, alpha=0.6)\n",
    "    plt.title(f'Weight Distribution: {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_weights(modelMLP, \"MLP\")\n",
    "plot_weights(modelKAN, \"KAN\")\n",
    "\n",
    "# 8g. FLOPs Comparison (using THOP)\n",
    "def calculate_flops(model):\n",
    "    dummy_input = torch.randn(1, 784).to(device)\n",
    "    flops, _ = profile(model, inputs=(dummy_input,))\n",
    "    return flops\n",
    "\n",
    "mlp_flops = calculate_flops(modelMLP)\n",
    "kan_flops = calculate_flops(modelKAN)\n",
    "print(f\"MLP FLOPs: {mlp_flops:,}\")\n",
    "print(f\"KAN FLOPs: {kan_flops:,}\")\n",
    "\n",
    "# 8h. (Optional) Simple MNIST Image + Prediction Visualization\n",
    "def show_predictions(model, loader, num_images=5):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            # Take the first batch only\n",
    "            images = images.to(device)\n",
    "            outputs = model(images.view(images.size(0), -1))\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for i in range(num_images):\n",
    "                # Reshape the i-th image from 1x28x28 -> 28x28\n",
    "                axes[i].imshow(images[i].cpu().squeeze(), cmap='gray')\n",
    "                axes[i].set_title(f'Pred: {preds[i].item()}')\n",
    "                axes[i].axis('off')\n",
    "            break\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(modelMLP, test_loader)  # Example using MLP\n",
    "show_predictions(modelKAN, test_loader)  # Example using KAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
