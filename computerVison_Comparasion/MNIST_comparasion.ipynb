{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Colab env\n",
    "Uploading and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting archspec==0.2.3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for Brotli (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [26 lines of output]\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-l044_c36\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:270: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\how2t\\AppData\\Local\\Temp\\pip-build-env-l044_c36\\overlay\\Lib\\site-packages\\setuptools\\dist.py:493: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'build-base' will not be supported in future\n",
      "              versions. Please use the underscore name 'build_base' instead.\n",
      "      \n",
      "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating bin\\lib.win-amd64-cpython-312\n",
      "      copying python\\brotli.py -> bin\\lib.win-amd64-cpython-312\n",
      "      running build_ext\n",
      "      <string>:67: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "      building '_brotli' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Brotli\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pycosat (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycosat\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (Brotli, pycosat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached archspec-0.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.4.1)\n",
      "Collecting boltons==23.0.0\n",
      "  Using cached boltons-23.0.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Brotli==1.0.9\n",
      "  Using cached Brotli-1.0.9.zip (510 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting charset-normalizer==2.0.4\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.2)\n",
      "Collecting cryptography==42.0.5\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting distro==1.9.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting executing==2.0.1\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting frozendict==2.4.2\n",
      "  Using cached frozendict-2.4.2-cp312-cp312-win_amd64.whl\n",
      "Collecting idna==3.7\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.19.1)\n",
      "Collecting jsonpatch==1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer==2.1\n",
      "  Using cached jsonpointer-2.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (1.6.0)\n",
      "Collecting packaging==23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.8.4)\n",
      "Collecting platformdirs==4.2.1\n",
      "  Using cached platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pluggy==1.0.0\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pycosat==0.6.6\n",
      "  Using cached pycosat-0.6.6.tar.gz (71 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: Pygments==2.18.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (2.18.0)\n",
      "Collecting PySocks==1.7.1\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting ruamel.yaml==0.17.21\n",
      "  Using cached ruamel.yaml-0.17.21-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.6.3)\n",
      "Collecting tqdm==4.66.4\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (5.14.3)\n",
      "Collecting truststore==0.8.0\n",
      "  Using cached truststore-0.8.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting urllib3==2.2.2\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting zstandard==0.22.0\n",
      "  Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pykan in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\projects\\kan_thesis\\envkan\\lib\\site-packages (from asttokens==2.4.1) (1.16.0)\n",
      "Collecting cffi>=1.12 (from cryptography==42.0.5)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.32.3)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached archspec-0.2.3-py3-none-any.whl (65 kB)\n",
      "Using cached boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
      "Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached platformdirs-4.2.1-py3-none-any.whl (17 kB)\n",
      "Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached truststore-0.8.0-py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl (511 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Building wheels for collected packages: Brotli, pycosat\n",
      "  Building wheel for Brotli (pyproject.toml): started\n",
      "  Building wheel for Brotli (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for pycosat (pyproject.toml): started\n",
      "  Building wheel for pycosat (pyproject.toml): finished with status 'error'\n",
      "Failed to build Brotli pycosat\n"
     ]
    }
   ],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0 \\\n",
    "pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up the Environment\n",
    "Starting with libs and setting up device. If possible use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from kan import KAN\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #normalizing dataset \n",
    "    ]) \n",
    "\n",
    "#Download MNIST dataset and used the transform to convert the data to tensor and normalize it\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create DataLoader to batch and shuffle the data using mulitprocessing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4096, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(width) - 1):\n",
    "            layers.append(nn.Linear(width[i], width[i+1]))\n",
    "            if i < len(width) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the MLP modelMLP\n",
    "modelMLP = MLP(width=[784, 10]).to(device)  \n",
    "modelKAN = KAN(width=[784, 10], grid=3, k=2, seed=42, device=device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizerMLP = torch.optim.Adam(modelMLP.parameters(), lr=0.001, weight_decay=1e-4) \n",
    "optimizerKAN = torch.optim.Adam(modelKAN.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]:  27%|██▋       | 4/15 [00:23<01:05,  5.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m optimizerKAN\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mdevice_type, enabled\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()):\n\u001b[1;32m---> 52\u001b[0m     outputs_KAN \u001b[38;5;241m=\u001b[39m \u001b[43mmodelKAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     loss_KAN \u001b[38;5;241m=\u001b[39m criterion(outputs_KAN, labels)\n\u001b[0;32m     55\u001b[0m scalerKAN\u001b[38;5;241m.\u001b[39mscale(loss_KAN)\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backward pass for KAN\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\kan\\MultKAN.py:785\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[1;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 785\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m#print(preacts, postacts_numerical, postspline)\u001b[39;00m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\kan\\KANLayer.py:157\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    154\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mexpand(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    156\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x) \u001b[38;5;66;03m# (batch, in_dim)\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcoef2curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    161\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m base[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\kan\\spline.py:76\u001b[0m, in \u001b[0;36mcoef2curve\u001b[1;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mconverting B-spline coefficients to B-spline curves. Evaluate x on B-spline curves (summing up B_batch results over B-spline basis).\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     75\u001b[0m b_splines \u001b[38;5;241m=\u001b[39m B_batch(x_eval, grid, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m---> 76\u001b[0m y_eval \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mijk,jlk->ijl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_splines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_splines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
      "File \u001b[1;32mc:\\Projects\\KAN_thesis\\envKAN\\Lib\\site-packages\\torch\\functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_amp = torch.cuda.is_available()\n",
    "\n",
    "scalerMLP = GradScaler(device='cuda', enabled=use_amp)\n",
    "scalerKAN = GradScaler(device='cuda', enabled=use_amp)\n",
    "\n",
    "train_losses_MLP = []\n",
    "train_losses_KAN = []\n",
    "test_accuracies_MLP = []\n",
    "test_accuracies_KAN = []\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 15  # Set to 1 for initial testing; adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set both models to training mode\n",
    "    modelMLP.train()\n",
    "    modelKAN.train()\n",
    "\n",
    "    # Initialize running loss and correct predictions counters\n",
    "    running_loss_MLP = 0.0\n",
    "    running_loss_KAN = 0.0\n",
    "    correct_MLP = 0\n",
    "    correct_KAN = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        # Move data to the configured device and flatten images\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ####### Training MLP #######\n",
    "        optimizerMLP.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=device_type, enabled=torch.cuda.is_available()):\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            loss_MLP = criterion(outputs_MLP, labels)\n",
    "\n",
    "        scalerMLP.scale(loss_MLP).backward()  # Backward pass for MLP\n",
    "        scalerMLP.step(optimizerMLP)          # Update MLP parameters\n",
    "        scalerMLP.update()\n",
    "\n",
    "        running_loss_MLP += loss_MLP.item() \n",
    "\n",
    "        _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "        correct_MLP += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "        ####### Training KAN #######\n",
    "        optimizerKAN.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=device_type, enabled=torch.cuda.is_available()):\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            loss_KAN = criterion(outputs_KAN, labels)\n",
    "\n",
    "        scalerKAN.scale(loss_KAN).backward()  # Backward pass for KAN\n",
    "        scalerKAN.step(optimizerKAN)           # Update KAN parameters\n",
    "        scalerKAN.update()\n",
    "\n",
    "        running_loss_KAN += loss_KAN.item()    # Accumulate KAN loss\n",
    "\n",
    "        _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "        correct_KAN += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate average losses for the epoch\n",
    "    avg_loss_MLP = running_loss_MLP / len(train_loader)\n",
    "    avg_loss_KAN = running_loss_KAN / len(train_loader)\n",
    "\n",
    "    train_losses_MLP.append(avg_loss_MLP)\n",
    "    train_losses_KAN.append(avg_loss_KAN)\n",
    "\n",
    "    ####### Evaluation #######\n",
    "    # Set both models to evaluation mode\n",
    "    modelMLP.eval()\n",
    "    modelKAN.eval()\n",
    "\n",
    "    correct_MLP_test = 0\n",
    "    correct_KAN_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Evaluate MLP\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "            correct_MLP_test += (predicted_MLP == labels).sum().item()\n",
    "            \n",
    "            # Evaluate KAN\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "            correct_KAN_test += (predicted_KAN == labels).sum().item()\n",
    "            \n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    # Calculate test accuracies\n",
    "    test_accuracy_MLP = 100 * correct_MLP_test / total_test\n",
    "    test_accuracy_KAN = 100 * correct_KAN_test / total_test\n",
    "\n",
    "    test_accuracies_MLP.append(test_accuracy_MLP)\n",
    "    test_accuracies_KAN.append(test_accuracy_KAN)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'| MLP Loss: {avg_loss_MLP:.4f} | MLP Test Acc: {test_accuracy_MLP:.2f}% '\n",
    "          f'| KAN Loss: {avg_loss_KAN:.4f} | KAN Test Acc: {test_accuracy_KAN:.2f}%')\n",
    "\n",
    "####### Plotting #######\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Training Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses_MLP, label='MLP Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), train_losses_KAN, label='KAN Training Loss', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Test Accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_MLP, label='MLP Test Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_KAN, label='KAN Test Accuracy', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
