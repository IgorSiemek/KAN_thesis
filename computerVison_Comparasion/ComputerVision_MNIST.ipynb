{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0 \\\n",
    "ptflops==0.7.4 \\\n",
    "pykan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 2: Imports & Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from kan import KAN  # Import your KAN implementation from pykan\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "# Decide CPU vs. GPU usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "use_amp = torch.cuda.is_available()  # We'll use Automatic Mixed Precision if on GPU\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 3: Dataset Transforms & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # Convert PIL image to Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize MNIST mean/std\n",
    "])\n",
    "\n",
    "# Download MNIST dataset (train/test). Store in './data'\n",
    "train_dataset = datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training and test sets\n",
    "# Large batch_size (4096/1024) to speed up training on GPU; adjust if memory is an issue\n",
    "train_loader = DataLoader(train_dataset, batch_size=4096, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 4: Define the MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(width) - 1):\n",
    "            layers.append(nn.Linear(width[i], width[i+1]))\n",
    "            if i < len(width) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 5: Instantiate MLP & KAN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example minimal architecture: [784, 8, 10]\n",
    "modelMLP = MLP(width=[784, 64, 10]).to(device)\n",
    "\n",
    "# KAN with same widths, plus TReLU config\n",
    "modelKAN = KAN(width=[784, 8, 10], grid=3, k=2, seed=42, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 6: Define Loss & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizerMLP = torch.optim.Adam(modelMLP.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "optimizerKAN = torch.optim.Adam(modelKAN.parameters(), lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 7: Main Training & Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = torch.cuda.is_available()\n",
    "\n",
    "scalerMLP = GradScaler(device='cuda', enabled=use_amp)\n",
    "scalerKAN = GradScaler(device='cuda', enabled=use_amp)\n",
    "\n",
    "train_losses_MLP = []\n",
    "train_losses_KAN = []\n",
    "test_accuracies_MLP = []\n",
    "test_accuracies_KAN = []\n",
    "\n",
    "num_epochs = 30  # For quick testing; set higher for better training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Switch models to training mode\n",
    "    modelMLP.train()\n",
    "    modelKAN.train()\n",
    "\n",
    "    running_loss_MLP = 0.0\n",
    "    running_loss_KAN = 0.0\n",
    "    correct_MLP = 0\n",
    "    correct_KAN = 0\n",
    "    total = 0\n",
    "\n",
    "    # ---- TRAINING LOOP ----\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        # Flatten MNIST images (N, 1, 28, 28) -> (N, 784)\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # MLP forward/backward\n",
    "        optimizerMLP.zero_grad()\n",
    "        with torch.autocast(device_type=device_type, enabled=use_amp):\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            loss_MLP = criterion(outputs_MLP, labels)\n",
    "        scalerMLP.scale(loss_MLP).backward()\n",
    "        scalerMLP.step(optimizerMLP)\n",
    "        scalerMLP.update()\n",
    "\n",
    "        running_loss_MLP += loss_MLP.item()\n",
    "        _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "        correct_MLP += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "        # KAN forward/backward\n",
    "        optimizerKAN.zero_grad()\n",
    "        with torch.autocast(device_type=device_type, enabled=use_amp):\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            loss_KAN = criterion(outputs_KAN, labels)\n",
    "        scalerKAN.scale(loss_KAN).backward()\n",
    "        scalerKAN.step(optimizerKAN)\n",
    "        scalerKAN.update()\n",
    "\n",
    "        running_loss_KAN += loss_KAN.item()\n",
    "        _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "        correct_KAN += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Average losses over the training set\n",
    "    avg_loss_MLP = running_loss_MLP / len(train_loader)\n",
    "    avg_loss_KAN = running_loss_KAN / len(train_loader)\n",
    "    train_losses_MLP.append(avg_loss_MLP)\n",
    "    train_losses_KAN.append(avg_loss_KAN)\n",
    "\n",
    "    # ---- EVALUATION LOOP ----\n",
    "    modelMLP.eval()\n",
    "    modelKAN.eval()\n",
    "    correct_MLP_test = 0\n",
    "    correct_KAN_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # MLP prediction\n",
    "            outputs_MLP = modelMLP(images)\n",
    "            _, predicted_MLP = torch.max(outputs_MLP, 1)\n",
    "            correct_MLP_test += (predicted_MLP == labels).sum().item()\n",
    "\n",
    "            # KAN prediction\n",
    "            outputs_KAN = modelKAN(images)\n",
    "            _, predicted_KAN = torch.max(outputs_KAN, 1)\n",
    "            correct_KAN_test += (predicted_KAN == labels).sum().item()\n",
    "\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    # Compute test-set accuracy\n",
    "    test_accuracy_MLP = 100 * correct_MLP_test / total_test\n",
    "    test_accuracy_KAN = 100 * correct_KAN_test / total_test\n",
    "    test_accuracies_MLP.append(test_accuracy_MLP)\n",
    "    test_accuracies_KAN.append(test_accuracy_KAN)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'| MLP Loss: {avg_loss_MLP:.4f} | MLP Test Acc: {test_accuracy_MLP:.2f}% '\n",
    "          f'| KAN Loss: {avg_loss_KAN:.4f} | KAN Test Acc: {test_accuracy_KAN:.2f}% '\n",
    "          f'| Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "# ---- Plot Loss & Accuracy ----\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses_MLP, label='MLP Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), train_losses_KAN, label='KAN Training Loss', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_MLP, label='MLP Test Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies_KAN, label='KAN Test Accuracy', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 8: Additional Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(kan_model):\n",
    "    \"\"\"\n",
    "    Sums absolute spline coefficients for the first KAN layer and plots a bar graph.\n",
    "    WARNING: This depends on the internal KAN structure (here we assume 'layers[0].splines').\n",
    "    \"\"\"\n",
    "    importance = torch.abs(kan_model.act_fun[0].coef).sum(dim=(0, 1))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.bar(range(importance.size(0)), importance.cpu().detach().numpy())\n",
    "    plt.title('Input Feature Importance (KAN)')\n",
    "    plt.xlabel('Pixel Position')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "\n",
    "feature_importance(modelKAN)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "mlp_params = count_parameters(modelMLP)\n",
    "kan_params = count_parameters(modelKAN)\n",
    "\n",
    "print(f\"MLP Parameters: {mlp_params:,}\")\n",
    "print(f\"KAN Parameters: {kan_params:,}\")\n",
    "\n",
    "# 4 bytes per float32 parameter\n",
    "print(f\"MLP Memory: {mlp_params * 4 / 1e6:.2f} MB\")\n",
    "print(f\"KAN Memory: {kan_params * 4 / 1e6:.2f} MB\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # MLP Inference Timing\n",
    "    start_infer_mlp = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        _ = modelMLP(images)\n",
    "    mlp_infer_time = time.time() - start_infer_mlp\n",
    "\n",
    "    # KAN Inference Timing\n",
    "    start_infer_kan = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        _ = modelKAN(images)\n",
    "    kan_infer_time = time.time() - start_infer_kan\n",
    "\n",
    "print(f\"MLP Inference Time (total over test set): {mlp_infer_time:.4f}s\")\n",
    "print(f\"KAN Inference Time (total over test set): {kan_infer_time:.4f}s\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "def plot_confusion_matrix(model, loader, model_name=\"Model\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    compute_metrics(cm)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(modelMLP, test_loader, \"MLP\")\n",
    "plot_confusion_matrix(modelKAN, test_loader, \"KAN\")\n",
    "\n",
    "def plot_weights(model, title):\n",
    "    weights = []\n",
    "    for param in model.parameters():\n",
    "        if param.dim() > 1:  # Skip biases\n",
    "            weights.extend(param.flatten().cpu().detach().numpy())\n",
    "    plt.hist(weights, bins=50, alpha=0.6)\n",
    "    plt.title(f'Weight Distribution: {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_weights(modelMLP, \"MLP\")\n",
    "plot_weights(modelKAN, \"KAN\")\n",
    "\n",
    "def calculate_flops(model):\n",
    "    dummy_input = torch.randn(1, 784).to(device)\n",
    "    macs, params = get_model_complexity_info(\n",
    "        model, (784,), as_strings=False, print_per_layer_stat=False\n",
    "    )\n",
    "    return macs\n",
    "\n",
    "mlp_flops = calculate_flops(modelMLP)\n",
    "kan_flops = calculate_flops(modelKAN)\n",
    "print(f\"MLP FLOPs: {mlp_flops:,}\")\n",
    "print(f\"KAN FLOPs: {kan_flops:,}\")\n",
    "\n",
    "def show_predictions(model, loader, num_images=5):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images.view(images.size(0), -1))\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for i in range(num_images):\n",
    "                axes[i].imshow(images[i].cpu().squeeze(), cmap='gray')\n",
    "                axes[i].set_title(f'Pred: {preds[i].item()}')\n",
    "                axes[i].axis('off')\n",
    "            break\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_metrics(cm):\n",
    "        \"\"\"Computes Precision, Recall, and F1-score from a confusion matrix.\"\"\"\n",
    "        num_classes = cm.shape[0]\n",
    "        precision = np.zeros(num_classes)\n",
    "        recall = np.zeros(num_classes)\n",
    "        f1_score = np.zeros(num_classes)\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "\n",
    "        macro_avg = {\n",
    "            \"Precision\": np.mean(precision),\n",
    "            \"Recall\": np.mean(recall),\n",
    "            \"F1-score\": np.mean(f1_score)\n",
    "        }\n",
    "\n",
    "        return precision, recall, f1_score, macro_avg\n",
    "\n",
    "\n",
    "    # ---- Generate Confusion Matrices from Existing Function ----\n",
    "    cm_mlp = confusion_matrix(all_labels, all_preds_mlp)  # Replace with actual computed labels\n",
    "    cm_kan = confusion_matrix(all_labels, all_preds_kan)  # Replace with actual computed labels\n",
    "\n",
    "    # Compute Precision, Recall, F1-score for each class\n",
    "    precision_mlp, recall_mlp, f1_mlp, macro_mlp = compute_metrics(cm_mlp)\n",
    "    precision_kan, recall_kan, f1_kan, macro_kan = compute_metrics(cm_kan)\n",
    "\n",
    "    # ---- Create DataFrames for Results ----\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Class\": range(10),\n",
    "        \"Precision_MLP\": precision_mlp,\n",
    "        \"Recall_MLP\": recall_mlp,\n",
    "        \"F1-score_MLP\": f1_mlp,\n",
    "        \"Precision_KAN\": precision_kan,\n",
    "        \"Recall_KAN\": recall_kan,\n",
    "        \"F1-score_KAN\": f1_kan\n",
    "    })\n",
    "\n",
    "    macro_df = pd.DataFrame({\n",
    "        \"Metric\": [\"Precision\", \"Recall\", \"F1-score\"],\n",
    "        \"MLP\": [macro_mlp[\"Precision\"], macro_mlp[\"Recall\"], macro_mlp[\"F1-score\"]],\n",
    "        \"KAN\": [macro_kan[\"Precision\"], macro_kan[\"Recall\"], macro_kan[\"F1-score\"]]\n",
    "    })\n",
    "\n",
    "    # ---- Print Metrics ----\n",
    "    print(\"\\nClass-wise Precision, Recall, and F1-score:\")\n",
    "    print(df_metrics)\n",
    "    print(\"\\nMacro-averaged Metrics:\")\n",
    "    print(macro_df)\n",
    "\n",
    "    # ---- Plot Precision, Recall, and F1-score for KAN vs MLP ----\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
    "\n",
    "    metrics = [\"Precision\", \"Recall\", \"F1-score\"]\n",
    "    mlp_values = [precision_mlp, recall_mlp, f1_mlp]\n",
    "    kan_values = [precision_kan, recall_kan, f1_kan]\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axes[i].bar(range(10), mlp_values[i], alpha=0.6, label=\"MLP\", color=\"blue\")\n",
    "        axes[i].bar(range(10), kan_values[i], alpha=0.6, label=\"KAN\", color=\"red\")\n",
    "        axes[i].set_xlabel(\"Class\")\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].set_title(f\"{metric} Comparison (MLP vs KAN)\")\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(modelMLP, test_loader)  # Example for MLP\n",
    "show_predictions(modelKAN, test_loader)  # Example for KAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
