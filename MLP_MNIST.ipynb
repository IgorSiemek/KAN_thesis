{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Colab env\n",
    "Uploading and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install archspec==0.2.3 \\\n",
    "asttokens==2.4.1 \\\n",
    "boltons==23.0.0 \\\n",
    "Brotli==1.0.9 \\\n",
    "charset-normalizer==2.0.4 \\\n",
    "colorama==0.4.6 \\\n",
    "comm==0.2.2 \\\n",
    "cryptography==42.0.5 \\\n",
    "decorator==4.4.2 \\\n",
    "distro==1.9.0 \\\n",
    "executing==2.0.1 \\\n",
    "frozendict==2.4.2 \\\n",
    "idna==3.7 \\\n",
    "jedi==0.19.1 \\\n",
    "jsonpatch==1.33 \\\n",
    "jsonpointer==2.1 \\\n",
    "nest-asyncio==1.6.0 \\\n",
    "packaging==23.2 \\\n",
    "parso==0.8.4 \\\n",
    "platformdirs==4.2.1 \\\n",
    "pluggy==1.0.0 \\\n",
    "pure-eval==0.2.2 \\\n",
    "pycosat==0.6.6 \\\n",
    "pycparser==2.21 \\\n",
    "Pygments==2.18.0 \\\n",
    "PySocks==1.7.1 \\\n",
    "requests==2.32.3 \\\n",
    "ruamel.yaml==0.17.21 \\\n",
    "stack-data==0.6.3 \\\n",
    "tqdm==4.66.4 \\\n",
    "traitlets==5.14.3 \\\n",
    "truststore==0.8.0 \\\n",
    "urllib3==2.2.2 \\\n",
    "zstandard==0.22.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up the Environment\n",
    "Starting with libs and setting up device. If possible use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess the MNIST Dataset\n",
    "We're loading MNIST dataset and apply all transformation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image -> Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #normalizing dataset \n",
    "    ]) \n",
    "\n",
    "#Download MNIST dataset and used the transform to convert the data to tensor and normalize it\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create DataLoader to batch and shuffle the data using mulitprocessing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2048, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the MLP Model\n",
    "Here we create our MLP model with dimension for MNIST dataset.\n",
    "Input set is only 784 pixels (images 28x28) and output size is 10\n",
    "Parameters\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(width) - 1):\n",
    "            layers.append(nn.Linear(width[i], width[i+1]))\n",
    "            if i < len(width) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the MLP model\n",
    "model = MLP(width=[784, 32, 16, 10]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Loss Function and Optimizer\n",
    "CrossEntropyLoss for classification and Adam optimizer for training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "This cell contains the training loop where the model is trained for a specified number of epochs. \n",
    "The loss is printed after each epoch to monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop parameters\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f'MLP Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Save training loss\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f'MLP Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model\n",
    "Finally, we evaluate the trained model on the test set to see how well it performs. The accuracy is calculated and printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few test set predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.view(images.size(0), -1).to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show a few images and their predictions\n",
    "images = images.view(-1, 28, 28).cpu().numpy()\n",
    "labels = labels.cpu().numpy()\n",
    "predicted = predicted.cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(f'Pred: {predicted[i]}, True: {labels[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
